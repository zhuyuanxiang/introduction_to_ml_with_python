# Ch03 无监督学习与预处理

## 3.1 无监督学习的类型

数据集的无监督变换（Unsupervised Transformation）是创建数据新的表示的算法，
与数据的原始表示相比，新的表示可能更容易被人或者其他机器学习算法理解。

无监督变换的常用方法：
- 降维（Dimensionality Reduction）：对于包含许多特征的数据的高维表示，
采用较少的特征对数据进行新的表示。
    - 降维的常见应用是将数据降为二维方便可视化。
- 聚类（Clustering）：将数据划分为不同的组，每组包含相似的内容。

## 3.2 无监督学习的困难

- 评估结果：没有标准，只能人工检查。

## 3.3 预处理与缩放

- StandardScaler    ：确保每个特征的平均值为0，方差为1，使所有特征都位于同一量级。
- RobustScaler      ：确保每个特征的统计属于都位于同一范围，中位数为0，四分位数为1？，从而忽略异常值
- MinMaxScaler      ：确保所有特征都位于0到1之间
- Normalizer        ：归一化。对每个数据点都进行缩放，使得特征向量的欧氏长度为1。
即将数据点都投向到半径为1的圆上。因此，只关注数据的方向（或角度），不关注数据的长度。

## 3.4 降维、特征提取与流形学习

降维的目的在于提取有用的特征，将每个数据点分解成一些分量的加权求和。

### 3.4.1 主成分分析（Principal Component Analysis，PCA）

PCA将数据分解成正交分量，并且能够解释尽可能多的数据方差。

### 3.4.2 非负矩阵分解（Non-negative Matrix Factorization，NMF）

- NMF将数据分解成非负分量，并且系数也是非负的。NMF的分量更容易解释。
- NMF设定的分量个数不一样，产生的分量的内容也不一样。
- NMF所有分量的地位平等。
- NMF比较适合于具有叠加结构的数据，包括：音频、基因表达和文本数据。

### 3.4.3 使用t-SNE进行流形学习

流形学习算法（Manifold Learning）是一类可以用于可视化的算法，允许更加复杂的映射，
给出更好的可视化效果。

t-SNE算法：计算训练数据的新的表示，不允许变换新的数据，不能用于测试集，只能用于变换训练集。
可以用于探索性数据分析，找到数据的二维表示，尽可能地保持数据点之间的距离。重点关注距离较近的点。

## 3.5 聚类

聚类（Clustering）将数据集划分成组，这些组叫做簇（Cluster）。通过划分数据，得到一个划分，
这个划分的簇内数据点相似，簇间数据点不同。

### 3.5.1 K均值聚类

K均值聚类：最简单、最常用的聚类算法之一。试图找出代表数据特定区域的簇中心。
算法步骤：
  - 随机初始化三个簇中心
  - 将每个数据点分配给最近的簇中心
  - 将每个簇中心设置为所分配的所有数据点的平均值
  - 如果簇的分配不再发生变化，那么算法结束。
  
1. K均值的失败案例：识别的簇要求必须是凸的（Convex），无法识别非球形簇。
2. K均值的失量量化（Vector Quantization）：
将K均值看作分解方法，每个点用单一分量来表示，即失量量化。
例如：将二维数据聚成10个簇中心，每个点到簇中心的距离作为一个特征，
这样就把2维特征的数据变换成10维特征的数据。

### 3.5.2 凝聚聚类（agglomerative clustering)

凝聚聚类，也叫AGNES（AGglomerative NESting），是层次聚类的一种，并且可以将层次聚类可视化为树状图。
是许多基于相同原则构建的聚类算法。

### 3.5.3 DBSCAN

具有噪声的基于密度的空间聚类应用：不需要预先设置簇的个数，可以划分具有复杂形状的簇，还可以找出不属于任何簇的点。

原理：识别特征空间中“拥挤”的区域，区域中的点靠近在一起，这些区域被称为特征空间中的密集区域。
- 密集区域内的点被称为核心样本。
- 与核心点的距离在eps的范围内的点被称为边界点。
- 不属于任何簇的点被称为噪声。

### 3.5.4 聚类算法的对比和评估

1. 用真实值评估聚类：ARI（adjusted rand index)和NMI(normalized mutual information)
2. 无真实值评估聚类：轮廓系数（silhouette coefficient），实际效果不好。
3. 在人脸数据集上比较算法：
    - DBSCAN：容易发现异常值（outlier），也容易找出相似图片的共性。
    - K均值：分类的簇中数据点个数更加均匀，距离较近的数据共性较强。
    - 凝聚聚类：容易得到共性更强的数据，也不容易受噪声影响。

### 3.5.5 聚类方法小结

聚类的应用和评估是一个定性的过程，主要应用在数据分析的探索阶段。
主要的三种聚类算法都可以控制聚类的粒度（granularity）：
- K均值：指定簇的数量，用簇的平均值来表示簇，
也可以看作分解方法，每个数据点由其簇中心表示。
- DBSCAN：定义接近程度，检测没有被分配到簇的“噪声点”，帮助自动判断簇的数量。
允许簇具有复杂的形状，可以生成大小判别很大的簇。
- 凝聚聚类：指定簇的数量。提供数据可能划分的整个层次结构，并且通过树状图查看。


# 3.6 小结与展望

无监督学习算法，可以用于探索性地数据分析和数据预处理，找出数据的正确表示。

分解、流形学习和聚类都是加深数据理解的重要工具 。
在没有监督信息的情况下，也是理解数据的仅有方法。
即使在监督学习中，探索性工具对于更好地理解数据性质也很重要。