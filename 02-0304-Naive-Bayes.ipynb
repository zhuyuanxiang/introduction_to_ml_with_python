{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 有监督学习算法\n",
    "### 2.3.4 朴素贝叶斯分类器\n",
    "\n",
    "朴素贝叶斯分类器基于「属性条件独立性假设」：对已知类别，假设所有属性相互独立，即每个属性独立地对分类结果产生影响。\n",
    "\n",
    "其数学公式如下：其中 $d$ 为属性数目，$x_i$ 为$\\mathbf{x}$在第$i$个属性上的取值\n",
    "\\begin{align*}\n",
    "P(y|x_1,\\cdots,x_n)=\\frac{P(y)P(x_1,\\cdots,x_n|y)}{P(x_1,\\cdots,x_n)}=\\frac{P(y)}{P(x_1,\\cdots,x_n)}\\prod_{i=1}^n P(x_i|y)\n",
    "\\end{align*}\n",
    "因为$P(x_1,\\cdots,x_n)$ 是常量，因此得到贝叶斯判定准则为：\n",
    "\\begin{align*}\n",
    "P(y|x_1,\\cdots,x_n)\n",
    "    &\\propto P(y)\\prod_{i=1}^n P(x_i|y)\\\\\n",
    "\\hat{y}\n",
    "    &=\\arg\\max_{y} P(y)\\prod_{i=1}^n P(x_i|y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 1, 0, 1],\n",
    "              [1, 0, 1, 1],\n",
    "              [0, 0, 0, 1],\n",
    "              [1, 0, 1, 0]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts:\n",
      " {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # iterate over each class\n",
    "    # count (sum) entries of 1 per feature\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"Feature counts:\\n\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优点、缺点和参数\n",
    "\n",
    "-   优点：\n",
    "    -   属于生成模型。训练速度更快，泛化能力稍差。\n",
    "    -   单独查看每个特征来学习参数，并且从每个特征中收集简单的类别统计数据。\n",
    "    -   对于高维稀疏数据的效果很好，对参数的鲁棒性也相对较好，是很好的基准模型，常常用于非常大的数据集\n",
    "-   Scikit-Learn 中实现了三种朴素 Bayes 分类器：\n",
    "    -   GaussianNB：应用于任意的高维的连续数据；\n",
    "        -   保存每个类别中每个特征的平均值和标准差\n",
    "    -   BernoulliNB：假定输入数据为稀疏的二分类数据；\n",
    "        -   计算每个类别中每个特征不为 0 的元素个数\n",
    "        -   主要用于文本数据分类\n",
    "    -   MultinomialNB：假定输入数据为计数数据 ( 即每个特征代表某个对象的整数计数，例如：一个单词在句子中出现的次数 )\n",
    "        -   计算每个类别中每个特征的平均值\n",
    "        -   主要用于文本数据分类\n",
    "-   参数\n",
    "    -   MultinomialNB 和 BernoulliNB 都只有一个参数 alpha，用于控制模型的复杂度\n",
    "        -   alpha：表示算法向数据中添加的虚拟数据点的个数，这些点对所有特征都取正值，从而将统计数据「平滑化」\n",
    "        -   alpha 越大，平滑性越强，模型复杂度越低，但是模型对 alpha 值的鲁棒性较好，即对模型的影响较小，调整这个参数会使模型的精度略有提高"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}