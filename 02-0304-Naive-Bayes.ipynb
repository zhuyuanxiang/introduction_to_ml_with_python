{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 有监督学习算法\n",
    "### 2.3.4 朴素贝叶斯分类器\n",
    "\n",
    "朴素贝叶斯分类器基于「属性条件独立性假设」：对已知类别，假设所有属性相互独立，即每个属性独立地对分类结果产生影响。\n",
    "\n",
    "其数学公式如下：其中 $d$ 为属性数目，$x_i$ 为$\\mathbf{x}$在第$i$个属性上的取值\n",
    "\\begin{align*}\n",
    "P(y|x_1,\\cdots,x_n)=\\frac{P(y)P(x_1,\\cdots,x_n|y)}{P(x_1,\\cdots,x_n)}=\\frac{P(y)}{P(x_1,\\cdots,x_n)}\\prod_{i=1}^n P(x_i|y)\n",
    "\\end{align*}\n",
    "因为$P(x_1,\\cdots,x_n)$ 是常量，因此得到贝叶斯判定准则为：\n",
    "\\begin{align*}\n",
    "P(y|x_1,\\cdots,x_n)\n",
    "    &\\propto P(y)\\prod_{i=1}^n P(x_i|y)\\\\\n",
    "\\hat{y}\n",
    "    &=\\arg\\max_{y} P(y)\\prod_{i=1}^n P(x_i|y)\n",
    "\\end{align*}\n",
    "使用最大后验估计(MAP)方法估计 $P(y)$ 和 $P(x_i|y)$。\n",
    "\n",
    "-   属于生成模型。训练速度更快，泛化能力稍差。\n",
    "-   单独查看每个特征来学习参数，并且从每个特征中收集简单的类别统计数据。\n",
    "-   Scikit-Learn 中实现了三种朴素 Bayes 分类器：不同的分类器的区别在于对 $P(x_i|y)$ 的分布的假设\n",
    "    -   GaussianNB：应用于任意的高维的连续数据；\n",
    "        -   保存每个类别中每个特征的平均值和标准差\n",
    "    -   BernoulliNB：假定输入数据为稀疏的二分类数据；\n",
    "        -   计算每个类别中每个特征不为 0 的元素个数\n",
    "        -   主要用于文本数据分类\n",
    "    -   MultinomialNB：假定输入数据为计数数据 ( 即每个特征代表某个对象的整数计数，例如：一个单词在句子中出现的次数 )\n",
    "        -   计算每个类别中每个特征的平均值\n",
    "        -   主要用于文本数据分类"
   ]
  },
  {
   "source": [
    "似然函数为：\n",
    "\\begin{align*}\n",
    "P(x_i|y)=\\frac1{\\sqrt{2\\pi\\sigma_y^2}}\\exp\\{-\\frac{(x_i-\\mu_y)^2}{2\\sigma_y^2}\\}\n",
    "\\end{align*}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of mislabeled points out of a total 75 points : 4\n"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "        % (X_test.shape[0], (y_test != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [0, 1, 0, 1],\n",
    "    [1, 0, 1, 1],\n",
    "    [0, 0, 0, 1],\n",
    "    [1, 0, 1, 0]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature counts:\n",
      " {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # iterate over each class\n",
    "    # count (sum) entries of 1 per feature\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "print(\"Feature counts:\\n\", counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strengths, weaknesses and parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}